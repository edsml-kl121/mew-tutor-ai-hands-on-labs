{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31112896",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.\n"
     ]
    }
   ],
   "source": [
    "from google.genai import types\n",
    "import os\n",
    "from google import genai\n",
    "api_key = os.environ.get(\"GEMINI_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"Please set the GEMINI_API_KEY environment variable\")\n",
    "\n",
    "client = genai.Client(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "268bc51b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The speaker begins by introducing the topic of Hugging Face, aiming to explain it to beginners who might only know it as an \"open-source hub for AI.\"\n",
      "\n",
      "He then elaborates on what Hugging Face is, stating it is a company founded by French individuals, currently valued at approximately $4.5 billion USD. The company's origin is tied to the popularity of \"Transformer architecture\" (not the series, but the foundation of Large Language Models). The initial goal was to build an open-source library to make it easy for people to use Transformer architecture. He conceptualizes Hugging Face as a \"Github of AI Model/data,\" providing a platform to discover and share AI models, datasets, collaborate, and access tools for fine-tuning models and learning.\n",
      "\n",
      "The speaker proceeds to demonstrate the Hugging Face website (`huggingface.co`).\n",
      "*   **Models:** He navigates to the \"Models\" section, showing filters for various tasks like \"Image-to-Text,\" \"Text Generation,\" and \"Time Series Forecasting.\" He selects a text generation model, \"Qwen3-Coder-480B-A35B-Instruct,\" and showcases its \"Model card\" which includes highlights, usage instructions with Python code snippets (using `transformers` library pipeline and direct loading), details on agentic coding, best practices, and citation information. He then shows the \"Files and versions\" tab, resembling a GitHub repository with commit history, file listings (including large `safetensors` model files of 4 GB each, noting the model size is 480 billion parameters), and licensing. He also highlights the \"Community\" tab, where users can discuss issues, ask questions, and provide feedback on models. He points out \"Use this model\" button which provides options to use the model in different environments like Google Colab or Kaggle notebooks, or deploy it via various \"Inference Providers\" or \"Spaces,\" and a \"Train\" button for further training.\n",
      "*   **Spaces:** Next, he moves to the \"Spaces\" section, described as \"The AI App Directory,\" which hosts interactive demos. He shows various running applications like \"Addit,\" \"PartCrafter,\" \"Audio Flamingo 3 Chat,\" and \"Qwen TTS Demo.\" He clicks on \"AudioRag Demo - Semantic Audio Search\" to illustrate an example of an interactive application where users can upload audio files and perform semantic searches.\n",
      "*   **Datasets:** Finally, he demonstrates the \"Datasets\" section, where users can find and upload datasets. He searches for \"thai\" datasets and shows \"iapp/thai_handwriting_dataset,\" displaying previews of images and their corresponding text and label files. He mentions that these datasets are used to train AI models. He also briefly shows the \"Open LLM Leaderboard\" within Spaces, which ranks different Large Language Models based on performance metrics.\n",
      "\n",
      "He concludes by summarizing the user journey on Hugging Face: discovering models, selecting and using them (via code), training/fine-tuning AI models, and uploading them to a personal repository on Hugging Face, including making demos available via \"Spaces,\" and leveraging leaderboards. He re-emphasizes that Hugging Face is a company focused on growing its platform by supporting the AI community.\n"
     ]
    }
   ],
   "source": [
    "response = client.models.generate_content(\n",
    "    model='models/gemini-2.5-flash',\n",
    "    contents=types.Content(\n",
    "        parts=[\n",
    "            types.Part(\n",
    "                file_data=types.FileData(file_uri='https://www.youtube.com/watch?v=YCjZ6jH4J7s&t=56s')\n",
    "            ),\n",
    "            types.Part(text='Summarize the content of the video comprehensively. ONLY Mention original content from the video. Do not make assumptions about the video.')\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c87e15",
   "metadata": {},
   "source": [
    "## Note "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gem-img",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
