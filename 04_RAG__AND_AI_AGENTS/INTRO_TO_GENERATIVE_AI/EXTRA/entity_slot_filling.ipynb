{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install colorama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google import genai\n",
    "import json\n",
    "import re\n",
    "from datetime import datetime\n",
    "from colorama import Fore, Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025/03/08 12:16\n"
     ]
    }
   ],
   "source": [
    "# Set up the Gemini client - ensure you have your API key set in environment variables\n",
    "api_key = os.environ.get(\"GEMINI_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"Please set the GEMINI_API_KEY environment variable\")\n",
    "\n",
    "client = genai.Client(api_key=api_key)\n",
    "# Get current datetime\n",
    "now = datetime.now()\n",
    "# Format datetime as \"YYYY/MM/DD HH:MM\"\n",
    "formatted_datetime = now.strftime(\"%Y/%m/%d %H:%M\")\n",
    "\n",
    "print(formatted_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def clean_string(response):\n",
    "    \"\"\"Clean the response string and convert it to a JSON object\"\"\"\n",
    "    # Step 1: Remove Markdown-like syntax (```json and ```)\n",
    "    cleaned_string = re.sub(r\"```(json)?\", \"\", response).strip()\n",
    "\n",
    "    # Step 2: Convert to JSON object\n",
    "    data = json.loads(cleaned_string)\n",
    "\n",
    "    # Step 3: Handle string `\"null\"` values\n",
    "    data = {key: None if value == \"null\" else value for key, value in data.items()}\n",
    "\n",
    "    return data\n",
    "\n",
    "def llm_call(prompt):\n",
    "    \"\"\"Call the LLM model with the given prompt\"\"\"\n",
    "    response = client.models.generate_content(\n",
    "        model='gemini-2.0-flash',\n",
    "        contents=prompt,\n",
    "    )\n",
    "    return response.text\n",
    "\n",
    "def check_slot(current_datetime, history, slots, user_query): # Augmented\n",
    "    \"\"\"Generate a response using Gemini based on the query and retrieved context\"\"\"\n",
    "    # model = genai.GenerativeModel(generation_model)\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "You are an AI assistant, reading the transcript of a conversation between an AI and a human.\n",
    "From the last line of the conversation, extract all proper named entity(here denoted as slots) that match about booking a flight.\n",
    "Named entities required for booking a flight include name, origin, destination, departure time.\n",
    "\n",
    "The output should be returned in the following json format.\n",
    "{{\n",
    "    \"name\": \"Define the human name identified from the conversation.\"\n",
    "    \"origin\": \"Define origin city identified from the conversation. Define only the city.\"\n",
    "    \"destination\": \"Define destination city identified from the conversation. Define only the city.\"\n",
    "    \"departure_time\": \"Define departure time identified from the conversation. Format should follow yyyy/mm/dd hh:mi\"\n",
    "}}\n",
    "\n",
    "If there is no match for each slot, assume null.(e.g., user is simply saying hello or having a brief conversation).\n",
    "\n",
    "EXAMPLE\n",
    "Conversation history:\n",
    "Person #1: I want to book a flight。\n",
    "AI: \"Hi，which city do you want to start your journey?\"\n",
    "Current Slots: {{\"name\": null, \"origin\": null, \"destination\": null, \"departure_time\": null}}\n",
    "Last line:\n",
    "Person #1: Shanghai\n",
    "Output Slots: {{\"name\": null, \"origin\": \"Shanghai\", \"destination\": null, \"departure_time\": null}}\n",
    "END OF EXAMPLE\n",
    "\n",
    "EXAMPLE\n",
    "Current datetime: 2023/04/10 11:20\n",
    "Conversation history:\n",
    "Person #1: I want to book a flight to Shanghai.\n",
    "AI: OK, what time do you want to start?\n",
    "Current Slots: {{\"name\": null, \"origin\": \"Shanghai\", \"destination\": null, \"departure_time\": null}}\n",
    "Last line:\n",
    "Person #1: Tomorrow at 8 a.m.\n",
    "Output Slots: {{\"name\": null, \"origin\": \"Shanghai\", \"destination\": null, \"departure_time\": \"2023/08/26 08:00\"}}\n",
    "END OF EXAMPLE\n",
    "\n",
    "Output Slots must be in json format!\n",
    "\n",
    "Begin!\n",
    "Current datetime: {current_datetime}\n",
    "Conversation history (for reference only):\n",
    "{history}\n",
    "Current Slots:\n",
    "{slots}\n",
    "Last line of conversation (for extraction):\n",
    "Human: {user_query}\n",
    "\n",
    "Output Slots:\"\"\"\n",
    "        \n",
    "    # response = client.models.generate_content(\n",
    "    #     model='gemini-2.0-flash',\n",
    "    #     contents=prompt,\n",
    "    # )\n",
    "    \n",
    "    return llm_call(prompt)\n",
    "\n",
    "def conversational_filling(current_slot):\n",
    "    prompt = f\"\"\"\n",
    "You are an assistant please take the current slot and write a question to let user fill in any missing information in the JSON\n",
    "{current_slot}\n",
    "Your question:\"\"\"\n",
    "    # response = client.models.generate_content(\n",
    "    #     model='gemini-2.0-flash',\n",
    "    #     contents=prompt,\n",
    "    # )\n",
    "    \n",
    "    return llm_call(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mPlease enter where you want to travel, from where and what time and what is your name?\u001b[0m\n",
      "\u001b[32mOkay, to complete your request, I need some more information. Could you please tell me the origin, destination, departure time for Mew?\n",
      "\u001b[0m\n",
      "{'name': 'Mew', 'origin': None, 'destination': None, 'departure_time': None}\n",
      "\u001b[32mOkay, I see you're planning a trip for \"นิว\". To help me fill in the missing details, could you please tell me: **Where is นิว traveling from, where is นิว going, and what time is นิว departing?**\n",
      "\u001b[0m\n",
      "{'name': 'นิว', 'origin': None, 'destination': None, 'departure_time': None}\n",
      "\u001b[32mWhat time would you like to depart?\n",
      "\u001b[0m\n",
      "{'name': 'นิว', 'origin': 'กรุงเทพ', 'destination': 'osaka', 'departure_time': None}\n",
      "\u001b[32mOkay, I see you're planning a trip from Bangkok to Osaka! To help me finalize your travel information, could you please tell me: **Do you have any preferred airlines or flight classes you would like to travel with?**\n",
      "\u001b[0m\n",
      "{'name': 'นิว', 'origin': 'กรุงเทพ', 'destination': 'osaka', 'departure_time': '2025/03/09 21:00'}\n",
      "```json\n",
      "{\n",
      "    \"name\": \"นิว\",\n",
      "    \"origin\": \"กรุงเทพ\",\n",
      "    \"destination\": \"osaka\",\n",
      "    \"departure_time\": \"2025/03/09 21:00\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "has_none = True\n",
    "chat_history = \"\"\n",
    "current_slot = {\"name\": None, \"origin\": None, \"destination\": None, \"departure_time\": None}\n",
    "print(Fore.GREEN + \"Please enter where you want to travel, from where and what time and what is your name?\" + Style.RESET_ALL)\n",
    "while has_none:\n",
    "    # Step 1: Get user input\n",
    "    user_query = input(\"Enter the last line of the conversation: \")\n",
    "    # Step 2: Call the Gemini model to check the slot\n",
    "    response = check_slot(formatted_datetime, chat_history, current_slot, user_query)\n",
    "    current_slot = clean_string(response) # Convert from String to Json\n",
    "    # Step 3: Store chat history\n",
    "    chat_history += f\"Human: {user_query}\\n\" \n",
    "    chat_history += f\"AI: {response}\\n\"\n",
    "    has_none = any(value is None for value in current_slot.values())\n",
    "    # Step 4: Explain what to fill\n",
    "    print(Fore.GREEN + conversational_filling(current_slot) + Style.RESET_ALL)\n",
    "    # Show sliot and print extra message.\n",
    "    print(current_slot)\n",
    "has_none\n",
    "print(response)\n",
    "\n",
    "# https://github.com/iMagist486/Chatbot-Slot-Filling/blob/main/chains/prompt.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mew-rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
