{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22ade15a-9c5b-45a0-981b-9e93a614991a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "print('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f8e3fb5e-fef3-4782-a1ed-a6d8b62353f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /opt/conda/lib/python3.10/site-packages (3.0.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from xgboost) (1.25.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12 in /opt/conda/lib/python3.10/site-packages (from xgboost) (2.26.2.post1)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from xgboost) (1.11.4)\n",
      "\u001b[33mWARNING: xgboost 3.0.0 does not provide the extra 'spark'\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost xgboost[spark]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "32088aba-16fd-4c59-96cd-1291946c2667",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "# 1. Start Spark session\n",
    "spark = SparkSession.builder.appName(\"XGBoostSparkExample\").getOrCreate()\n",
    "\n",
    "# 2. Create a small sample dataset\n",
    "data = [\n",
    "    (1.0, 2.0, 0),\n",
    "    (2.0, 1.0, 1),\n",
    "    (1.5, 1.5, 0),\n",
    "    (3.0, 3.0, 1),\n",
    "    (2.5, 0.5, 1)\n",
    "]\n",
    "\n",
    "df = spark.createDataFrame(data, [\"feature1\", \"feature2\", \"label\"])\n",
    "\n",
    "# 3. Assemble features into a single vector\n",
    "assembler = VectorAssembler(inputCols=[\"feature1\", \"feature2\"], outputCol=\"features\")\n",
    "df = assembler.transform(df).select(\"features\", \"label\")\n",
    "\n",
    "# 4. Train-test split\n",
    "train_df, test_df = df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe59645c-89a6-4ae0-9454-290e83b6a0da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorAssembler_104c314d60b8"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72c193d8-50c4-4327-b143-7abe9c9a5575",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "| features|label|\n",
      "+---------+-----+\n",
      "|[1.0,2.0]|    0|\n",
      "|[2.0,1.0]|    1|\n",
      "|[1.5,1.5]|    0|\n",
      "|[3.0,3.0]|    1|\n",
      "|[2.5,0.5]|    1|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "528a340a-9b32-4d73-a738-33c846c9bd97",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "| features|label|\n",
      "+---------+-----+\n",
      "|[1.0,2.0]|    0|\n",
      "|[2.0,1.0]|    1|\n",
      "|[2.5,0.5]|    1|\n",
      "|[3.0,3.0]|    1|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c9c3de0-c216-4783-9ede-fe1ad1722824",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "| features|label|\n",
      "+---------+-----+\n",
      "|[1.5,1.5]|    0|\n",
      "+---------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "test_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "77c187d7-562c-4ed7-96ef-2d670df819c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/02 08:55:59 WARN DecisionTreeMetadata: DecisionTree reducing maxBins from 32 to 4 (= number of training instances)\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# 5. Train XGBoost model\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", numTrees=100, maxDepth=5)\n",
    "rf_model = rf.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8dfc950e-1b15-4d97-8acb-d0cb9d2f761b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 36:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+-------------+-----------+----------+\n",
      "| features|label|rawPrediction|probability|prediction|\n",
      "+---------+-----+-------------+-----------+----------+\n",
      "|[1.5,1.5]|    0|  [71.0,29.0]|[0.71,0.29]|       0.0|\n",
      "+---------+-----+-------------+-----------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# 6. Inference (Prediction)\n",
    "predictions = rf_model.transform(test_df)\n",
    "predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05ac7cde-c34b-4afd-964c-0283fe04559b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# probability: [0.71,0.29]\n",
    "# Class 0: 71% confidence\n",
    "# Class 1: 29% confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cca62d4b-99c5-4180-9577-335c0a8494ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Save to a folder (not a file)\n",
    "rf_model.write().overwrite().save(\"rf_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3de05dce-b2cf-4b4f-b16e-fa6b834b6441",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassificationModel\n",
    "\n",
    "loaded_rf_model = RandomForestClassificationModel.load(\"rf_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a64231f5-e37c-4b85-960d-8de9449f436f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+----------+-----------+\n",
      "| features|label|prediction|probability|\n",
      "+---------+-----+----------+-----------+\n",
      "|[1.5,1.5]|    0|       0.0|[0.71,0.29]|\n",
      "+---------+-----+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loaded_rf_model.transform(test_df).select(\"features\", \"label\", \"prediction\", \"probability\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4e23d6-8ad4-4b59-b1cf-782147450323",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark (Local)",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
